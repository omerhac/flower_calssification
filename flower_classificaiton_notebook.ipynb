{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flower_classificaiton_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omerhac/flower_calssification/blob/master/flower_classificaiton_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USMM_qfjDu8-",
        "colab_type": "code",
        "outputId": "9314f2ee-b89a-4191-8ce6-f6fb69f52cb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import math, os, sys, re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "if 'google.colab' in sys.modules: # Colab-only Tensorflow version selector\n",
        "  %tensorflow_version 2.x\n",
        "print(\"tf version: \" + tf.__version__)\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version: 2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn3EgdyMHxAG",
        "colab_type": "text"
      },
      "source": [
        "# Hardware detection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0A8eT_2Ew9l",
        "colab_type": "code",
        "outputId": "1b1ec373-1a32-4d37-cdce-70f3698e6b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "    \n",
        "# Select appropriate distribution strategy for hardware\n",
        "if tpu:\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print('Running on TPU ', tpu.master())  \n",
        "elif len(gpus) > 0:\n",
        "  strategy = tf.distribute.MirroredStrategy(gpus) # this works for 1 to multiple GPUs\n",
        "  print('Running on ', len(gpus), ' GPU(s) ')\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "\n",
        "# How many accelerators do we have ?\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.94.229.178:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.94.229.178:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  grpc://10.94.229.178:8470\n",
            "Number of accelerators:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qdxH0sFg0O4",
        "colab_type": "text"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX6iy3LZdNM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_numpy_batch(dataset, n_samples):\n",
        "  \"\"\"get numpy array of n samples\"\"\"\n",
        "  dataset = dataset.shuffle(buffer_size=10)\n",
        "  batched = dataset.batch(n_samples)\n",
        "  for images, labels in batched:\n",
        "    return images.numpy(), labels.numpy()\n",
        "\n",
        "def show_n_samples(dataset, n):\n",
        "  \"\"\"prints n images and labels\"\"\"\n",
        "  plt.figure(figsize = (2 * n, 2 *n))\n",
        "\n",
        "  rows = math.ceil(n / 3)\n",
        "\n",
        "  batch_images, batch_labels = get_numpy_batch(dataset, n)\n",
        "\n",
        "  for i, image in enumerate(batch_images):\n",
        "    plt.subplot(rows, 3, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(CLASSES[batch_labels[i]])\n",
        "  \n",
        "  plt.show()\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "def count_dataset_items(dataset):\n",
        "  # counts items iterativly in the data set. requaiers some time...\n",
        "  count = 0\n",
        "  for obj in dataset:\n",
        "    count += 1\n",
        "  \n",
        "  return count\n",
        "\n",
        "def display_training_curves(hist, with_val=False):\n",
        "  \"\"\"display learning curves for keras history dict, args: history dict, with val --> boolean with/without val\"\"\"\n",
        "  plt.figure(figsize=(18,6))\n",
        "\n",
        "  # accuracy plots\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(hist['accuracy'])\n",
        "  \n",
        "  if with_val:\n",
        "    plt.plot(hist['val_accuracy'])\n",
        "    plt.legend(['Train', 'Validation'])\n",
        "  \n",
        "  else:\n",
        "    plt.legend(['Train'])\n",
        "  \n",
        "  plt.title('Model accuracy')\n",
        "  plt.xlabel('EPOCH')\n",
        "  plt.ylabel('Accuracy')\n",
        "\n",
        "  # loss plots\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(hist['loss'])\n",
        "\n",
        "  if with_val:\n",
        "    plt.plot(hist['val_loss'])\n",
        "    plt.legend(['Train loss', 'Val loss'])\n",
        "  \n",
        "  else:\n",
        "    plt.legend(['Train loss'])\n",
        "  \n",
        "  plt.title('Model loss')\n",
        "  plt.xlabel('EPOCH')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.show()\n",
        "\n",
        "def display_training_curves_without_dict(accuracy, val_accuracy, loss, val_loss):\n",
        "  \"\"\"display learning curves. args: accuracy iterable, val iterable , loss iterable, val_los iterable\"\"\"\n",
        "  keras_dict = {'accuracy': accuracy, 'val_accuracy': val_accuracy, 'loss': loss, 'val_loss': val_loss}\n",
        "  return display_training_curves(keras_dict)\n",
        "\n",
        "  \n",
        "def display_model_predictions(model, dataset):\n",
        "  \"\"\"Displays 9 images and their predictions\"\"\"\n",
        "\n",
        "  batch_images, batch_labels = get_numpy_batch(dataset, 9)\n",
        "  predictions = model.predict(batch_images) # predict images labels\n",
        "  \n",
        "  plt.figure(figsize=(18,18))\n",
        "\n",
        "  for i, image in enumerate(batch_images):\n",
        "    # def plot\n",
        "    plt.subplot(3,3,i + 1)\n",
        "    plt.imshow(image)\n",
        "\n",
        "    # write prediction as titles\n",
        "    pred =np.argmax(predictions[i])\n",
        "    if pred == batch_labels[i]:\n",
        "      plt.title(CLASSES[pred], fontdict={'color':'g'})\n",
        "\n",
        "    else:\n",
        "      plt.title(CLASSES[pred] + \" WRONG --> \" + CLASSES[batch_labels[i]], fontdict={'color': 'r'})\n",
        "    \n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZX-QcX8TRLN",
        "colab_type": "text"
      },
      "source": [
        "# Loading images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YvIAPRyVMBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read tfrecords from gcs\n",
        "def read_tfrecord(example):\n",
        "  \"\"\"Parses one tf record to image, class, one_hot_class\"\"\"\n",
        "  features = {\n",
        "      \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"class\": tf.io.FixedLenFeature([], tf.int64),\n",
        "  }\n",
        "\n",
        "  example = tf.io.parse_example(example, features)\n",
        "  image = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "  image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "  image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size will be needed for TPU\n",
        "  label = tf.cast(example['class'], tf.int32)\n",
        "  return image, label\n",
        "\n",
        "def load_tfrecord_dataset(dataset_filenames):\n",
        "  \"\"\"Loads a TFRecord dataset. args: dataset_filnames --> list of strings of files paths\"\"\"\n",
        "\n",
        "  # allows for no order parallel reading\n",
        "  option_no_order = tf.data.Options()\n",
        "  option_no_order.experimental_deterministic = False\n",
        "\n",
        "  dataset = tf.data.TFRecordDataset(dataset_filenames, num_parallel_reads=AUTO)\n",
        "  dataset = dataset.with_options(option_no_order)\n",
        "  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "  return dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZm3SAkOyLtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting image paths\n",
        "IMAGE_SIZE = [512, 512]\n",
        "\n",
        "GCS_PATH = \"gs://kds-b2e6cdbc4af76dcf0363776c09c12fe46872cab211d1de9f60ec7aec\" # GCS path for competition data\n",
        "\n",
        "# dict for paths to different image sizes\n",
        "GCS_PATH_SELECT = { # available image sizes\n",
        "    192: GCS_PATH + '/tfrecords-jpeg-192x192',\n",
        "    224: GCS_PATH + '/tfrecords-jpeg-224x224',\n",
        "    331: GCS_PATH + '/tfrecords-jpeg-331x331',\n",
        "    512: GCS_PATH + '/tfrecords-jpeg-512x512'\n",
        "}\n",
        "\n",
        "# get full path with image size and split to train / val / test\n",
        "GCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n",
        "\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n",
        "TRAINING_FILENAMES = TRAINING_FILENAMES + TRAINING_FILENAMES\n",
        "VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n",
        "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') # predictions on this dataset should be submitted for the competition\n",
        "\n",
        "# get length of datasets\n",
        "TRAINING_LENGTH = count_data_items(TRAINING_FILENAMES)\n",
        "VALIDATION_LENGTH = count_data_items(VALIDATION_FILENAMES)\n",
        "TEST_LENGTH = count_data_items(TEST_FILENAMES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMJ0psj1ZLMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "whole_dataset = load_tfrecord_dataset(TRAINING_FILENAMES + VALIDATION_FILENAMES + TEST_FILENAMES)\n",
        "training_dataset = load_tfrecord_dataset(TRAINING_FILENAMES)\n",
        "validation_dataset = load_tfrecord_dataset(VALIDATION_FILENAMES)\n",
        "#test_dataset = load_tfrecord_dataset(TEST_FILENAMES) # have to create a function to load test items from tfrecord\n",
        "\n",
        "# batch datset\n",
        "BATCH_SIZE = 128\n",
        "STEPS_PER_EPOCH = TRAINING_LENGTH // BATCH_SIZE\n",
        "batched_whole_dataset = whole_dataset.batch(BATCH_SIZE)\n",
        "batched_training_dataset = training_dataset.batch(BATCH_SIZE)\n",
        "batched_validation_dataset = validation_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRvh9z_1sMPj",
        "colab_type": "text"
      },
      "source": [
        "## Flower classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O53AaKRw0ihG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n",
        "           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n",
        "           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n",
        "           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n",
        "           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n",
        "           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n",
        "           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n",
        "           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n",
        "           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n",
        "           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n",
        "           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAIFHa-WbyIb",
        "colab_type": "text"
      },
      "source": [
        "# Simple transfer learning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6FfS32qhxIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pretrained_model():\n",
        "  # get xception pretrained model\n",
        "  xception = keras.applications.Xception(include_top=False, input_shape=[*IMAGE_SIZE,3])\n",
        "  xception.trainable = False\n",
        "\n",
        "  # define model\n",
        "  simple_model = keras.models.Sequential([\n",
        "    xception,\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    #keras.layers.Flatten(),\n",
        "    keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  simple_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return simple_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUPw5N73elYj",
        "colab_type": "code",
        "outputId": "de9a56b6-19ff-44f7-905b-4ef66878b701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "with strategy.scope():\n",
        "  model = get_pretrained_model()\n",
        "  model.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Model)             (None, 16, 16, 2048)      20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_11  (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 104)               213096    \n",
            "=================================================================\n",
            "Total params: 21,074,576\n",
            "Trainable params: 213,096\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c2b68277-c5b1-4a83-8999-4b79dcdd87fe",
        "id": "jjzneidWU68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "hist = model.fit(batched_training_dataset, epochs=10, validation_data=batched_validation_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "     18/Unknown - 268s 15s/step - loss: 4.6115 - accuracy: 0.0200"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tCiFwXMhOT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_training_curves(hist.history, with_val=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_J3bcH2LDSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_model_predictions(model, validation_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGN9A73Zdjh0",
        "colab_type": "text"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFgKgJRvdntA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_image(image, label):\n",
        "  \"\"\"Randomly flip and saturate an image. args: image, label\"\"\"\n",
        "  aug_image = tf.image.random_flip_left_right(image)\n",
        "  aug_image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "\n",
        "  return aug_image, label\n",
        "\n",
        "\n",
        "def augment_tf_dataset(dataset):\n",
        "  double_data = dataset\n",
        "  \n",
        "  return double_data.map(augment_image, num_parallel_calls=AUTO)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7euG1ubayMlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = augment_tf_dataset(training_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBMLF3iE7U9E",
        "colab_type": "text"
      },
      "source": [
        "# Transfer learning with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Rnb9g97hsb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "e141bc56-8027-445a-84af-1d35c629b7f6"
      },
      "source": [
        "def step_lr_schedule(epoch, current, decay_rate=1, initial_lr=1e-5, linear_slope= 1e-5, peak_slope=5):\n",
        "  \"\"\"transfer learning step scheduler. args: epoch number, curren learning rate\"\"\"\n",
        "  if epoch <= peak_slope:\n",
        "    return initial_lr + linear_slope * epoch\n",
        "  else:\n",
        "    return current *math.exp((peak_slope-epoch))\n",
        "\n",
        "def get_transfer_learning_schedule(decay_rate=1, initial_lr=1e-5, linear_slope=1e-5, peak_slope=5):\n",
        "  \"\"\"Get a learning rate step scheduler. args: parameters for the step curve\"\"\"\n",
        "  return lambda epoch, current: step_lr_schedule(epoch, current, decay_rate, initial_lr, linear_slope, peak_slope)\n",
        "\n",
        "\n",
        "transfer_lr_schedule = get_transfer_learning_schedule(decay_rate=1, initial_lr=1e-6, linear_slope=1e-5, peak_slope=6)\n",
        "schedule = keras.callbacks.LearningRateScheduler(lambda epoch: 1e-5, verbose=1)\n",
        "\n",
        "# visualize lr\n",
        "current = 0\n",
        "lrs = []\n",
        "for i in range(10):\n",
        "  lr = transfer_lr_schedule(i, current)\n",
        "  current = lr\n",
        "  lrs.append(lr)\n",
        "\n",
        "plt.plot(range(10), lrs)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5cb1a6ea58>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAuIxlp49Udg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_trainable_pretrained_model():\n",
        "  # get xception pretrained model\n",
        "  xception = keras.applications.MobileNetV2(include_top=False, input_shape=[*IMAGE_SIZE,3])\n",
        "  xception.trainable = True\n",
        "\n",
        "  # define model\n",
        "  simple_model = keras.models.Sequential([\n",
        "    xception,\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    #keras.layers.Flatten(),\n",
        "    keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  simple_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  return simple_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incuKt59-G4E",
        "colab_type": "code",
        "outputId": "419423b7-bfa6-4613-be27-7606cabbba9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "with strategy.scope():\n",
        "  trainable_model = get_trainable_pretrained_model()\n",
        "  trainable_model.summary()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_224 (Model) (None, 16, 16, 1280)      2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_10  (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 104)               133224    \n",
            "=================================================================\n",
            "Total params: 2,391,208\n",
            "Trainable params: 2,357,096\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj1vd1sr-Y_3",
        "colab_type": "code",
        "outputId": "2ffe8fcd-a6a6-4634-a31a-0e3116e6ae7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "hist = trainable_model.fit(batched_training_dataset, epochs = 10, validation_data=batched_validation_dataset, callbacks=[schedule])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 77s 384ms/step - loss: 4.2728 - accuracy: 0.1025 - val_loss: nan - val_accuracy: 0.0213 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 2/10\n",
            " 85/200 [===========>..................] - ETA: 26s - loss: nan - accuracy: 0.0201"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-f9d6426621e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_training_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatched_validation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EizdNda7wtBK",
        "colab_type": "text"
      },
      "source": [
        "# Custom cnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elE2A6pAwsF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "7cb3608c-667d-42f8-fb6a-c231a21c4331"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, GlobalAveragePooling2D, BatchNormalization, MaxPooling2D, concatenate, Input\n",
        "from tensorflow.keras import  Model\n",
        "\n",
        "def inception_block(x, num_3_filters, num_1_filters, batch_norm_moment = 0.9):\n",
        "  side_pool = MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "  # middle branch\n",
        "  middle_branch_1 = Conv2D(num_1_filters, kernel_size=(1,1), strides=(1,1), activation = 'relu', padding='same')(x)\n",
        "  middle_branch_1 = BatchNormalization(momentum=batch_norm_moment)(middle_branch_1)\n",
        "  middle_branch_3 = Conv2D(num_3_filters, kernel_size=(3,3), strides=(2,2), activation='relu', padding='same')(middle_branch_1)\n",
        "  middle_branch_3 = BatchNormalization(momentum=batch_norm_moment)(middle_branch_3)\n",
        "\n",
        "  # big branch\n",
        "  big_branch_1 = Conv2D(num_1_filters, kernel_size=(1,1), strides=(1,1), activation = 'relu', padding='same')(x)\n",
        "  big_branch_1 = BatchNormalization(momentum=batch_norm_moment)(big_branch_1)\n",
        "  big_branch_3_1 = Conv2D(num_3_filters, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(big_branch_1)\n",
        "  big_branch_3_1 = BatchNormalization(momentum=batch_norm_moment)(big_branch_3_1)\n",
        "  big_branch_3_2 = Conv2D(num_3_filters, kernel_size=(3,3), strides=(2,2), activation='relu', padding='same')(big_branch_3_1)\n",
        "  big_branch_3_2 = BatchNormalization(momentum=batch_norm_moment)(big_branch_3_2)\n",
        "\n",
        "  depth_concat = concatenate([side_pool, middle_branch_3, big_branch_3_2])\n",
        "  \n",
        "  return depth_concat\n",
        "\n",
        "def inception(num_3_filters, num_1_filters, batch_norm_moment = 0.9):\n",
        "  return lambda x: inception_block(x, num_3_filters, num_1_filters, batch_norm_moment = 0.9)\n",
        "\n",
        "x = Input(shape=[*IMAGE_SIZE, 3])\n",
        "c1 = Conv2D(6, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "i1 = inception(24,12)(c1)\n",
        "g = GlobalAveragePooling2D()(i1)\n",
        "d = Dense(len(CLASSES), activation='softmax')(g)\n",
        "model = Model(inputs=x, outputs=d)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_30 (InputLayer)           [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 512, 512, 6)  168         input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 512, 512, 12) 84          conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 512, 512, 12) 48          conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 512, 512, 12) 84          conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 512, 512, 24) 2616        batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 512, 512, 12) 48          conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 512, 512, 24) 96          conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 256, 256, 24) 2616        batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 256, 256, 24) 5208        batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 256, 256, 6)  0           conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 256, 256, 24) 96          conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 256, 256, 24) 96          conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 256, 256, 54) 0           max_pooling2d_3[0][0]            \n",
            "                                                                 batch_normalization_52[0][0]     \n",
            "                                                                 batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_15 (Gl (None, 54)           0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 104)          5720        global_average_pooling2d_15[0][0]\n",
            "==================================================================================================\n",
            "Total params: 16,880\n",
            "Trainable params: 16,688\n",
            "Non-trainable params: 192\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgaHQCWOuWWw",
        "colab_type": "text"
      },
      "source": [
        "# Apply object detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLL7TKnjQDp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/endernewton/tf-faster-rcnn.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMdjIFZrvGu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}