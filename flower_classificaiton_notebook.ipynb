{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flower_classificaiton_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omerhac/flower_calssification/blob/master/flower_classificaiton_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USMM_qfjDu8-",
        "colab_type": "code",
        "outputId": "7d4ebcd4-6ef4-4a60-b247-660ac747f9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import math, os, sys, re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "if 'google.colab' in sys.modules: # Colab-only Tensorflow version selector\n",
        "  %tensorflow_version 2.x\n",
        "print(\"tf version: \" + tf.__version__)\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version: 2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn3EgdyMHxAG",
        "colab_type": "text"
      },
      "source": [
        "# Hardware detection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0A8eT_2Ew9l",
        "colab_type": "code",
        "outputId": "35a5b19e-3281-4636-9209-9aa4b89e390b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "    \n",
        "# Select appropriate distribution strategy for hardware\n",
        "if tpu:\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print('Running on TPU ', tpu.master())  \n",
        "elif len(gpus) > 0:\n",
        "  strategy = tf.distribute.MirroredStrategy(gpus) # this works for 1 to multiple GPUs\n",
        "  print('Running on ', len(gpus), ' GPU(s) ')\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "\n",
        "# How many accelerators do we have ?\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.58.13.130:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.58.13.130:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  grpc://10.58.13.130:8470\n",
            "Number of accelerators:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qdxH0sFg0O4",
        "colab_type": "text"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX6iy3LZdNM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_numpy_batch(dataset, n_samples):\n",
        "  \"\"\"get numpy array of n samples\"\"\"\n",
        "  dataset = dataset.shuffle(buffer_size=10)\n",
        "  batched = dataset.batch(n_samples)\n",
        "  for images, labels in batched:\n",
        "    return images.numpy(), labels.numpy()\n",
        "\n",
        "def show_n_samples(dataset, n):\n",
        "  \"\"\"prints n images and labels\"\"\"\n",
        "  plt.figure(figsize = (2 * n, 2 *n))\n",
        "\n",
        "  rows = math.ceil(n / 3)\n",
        "\n",
        "  batch_images, batch_labels = get_numpy_batch(dataset, n)\n",
        "\n",
        "  for i, image in enumerate(batch_images):\n",
        "    plt.subplot(rows, 3, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(CLASSES[batch_labels[i]])\n",
        "  \n",
        "  plt.show()\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "def count_dataset_items(dataset):\n",
        "  # counts items iterativly in the data set. requaiers some time...\n",
        "  count = 0\n",
        "  for obj in dataset:\n",
        "    count += 1\n",
        "  \n",
        "  return count\n",
        "\n",
        "def display_training_curves(hist, metric='accuracy', with_val=False):\n",
        "  \"\"\"display learning curves for keras history dict, args: history dict, with val --> boolean with/without val\"\"\"\n",
        "  plt.figure(figsize=(18,6))\n",
        "\n",
        "  # accuracy plots\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(hist[metric])\n",
        "  \n",
        "  if with_val:\n",
        "    plt.plot(hist['val_' + metric])\n",
        "    plt.legend(['Train', 'Validation'])\n",
        "  \n",
        "  else:\n",
        "    plt.legend(['Train'])\n",
        "  \n",
        "  plt.title('Model accuracy')\n",
        "  plt.xlabel('EPOCH')\n",
        "  plt.ylabel('Accuracy')\n",
        "\n",
        "  # loss plots\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(hist['loss'])\n",
        "\n",
        "  if with_val:\n",
        "    plt.plot(hist['val_loss'])\n",
        "    plt.legend(['Train loss', 'Val loss'])\n",
        "  \n",
        "  else:\n",
        "    plt.legend(['Train loss'])\n",
        "  \n",
        "  plt.title('Model loss')\n",
        "  plt.xlabel('EPOCH')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.show()\n",
        "\n",
        "def display_training_curves_without_dict(accuracy, val_accuracy, loss, val_loss):\n",
        "  \"\"\"display learning curves. args: accuracy iterable, val iterable , loss iterable, val_los iterable\"\"\"\n",
        "  keras_dict = {'accuracy': accuracy, 'val_accuracy': val_accuracy, 'loss': loss, 'val_loss': val_loss}\n",
        "  return display_training_curves(keras_dict)\n",
        "\n",
        "  \n",
        "def display_model_predictions(model, dataset):\n",
        "  \"\"\"Displays 9 images and their predictions\"\"\"\n",
        "\n",
        "  batch_images, batch_labels = get_numpy_batch(dataset, 9)\n",
        "  predictions = model.predict(batch_images) # predict images labels\n",
        "  \n",
        "  plt.figure(figsize=(18,18))\n",
        "\n",
        "  for i, image in enumerate(batch_images):\n",
        "    # def plot\n",
        "    plt.subplot(3,3,i + 1)\n",
        "    plt.imshow(image)\n",
        "\n",
        "    # write prediction as titles\n",
        "    pred =np.argmax(predictions[i])\n",
        "    if pred == batch_labels[i]:\n",
        "      plt.title(CLASSES[pred], fontdict={'color':'g'})\n",
        "\n",
        "    else:\n",
        "      plt.title(CLASSES[pred] + \" WRONG --> \" + CLASSES[batch_labels[i]], fontdict={'color': 'r'})\n",
        "    \n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZX-QcX8TRLN",
        "colab_type": "text"
      },
      "source": [
        "# Loading images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YvIAPRyVMBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read tfrecords from gcs\n",
        "def read_tfrecord(example):\n",
        "  \"\"\"Parses one tf record to image, class, one_hot_class\"\"\"\n",
        "  features = {\n",
        "      \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"class\": tf.io.FixedLenFeature([], tf.int64),\n",
        "  }\n",
        "\n",
        "  example = tf.io.parse_example(example, features)\n",
        "  image = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "  image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "  image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size will be needed for TPU\n",
        "  label = tf.cast(example['class'], tf.int32)\n",
        "  return image, label\n",
        "\n",
        "def load_tfrecord_dataset(dataset_filenames):\n",
        "  \"\"\"Loads a TFRecord dataset. args: dataset_filnames --> list of strings of files paths\"\"\"\n",
        "\n",
        "  # allows for no order parallel reading\n",
        "  option_no_order = tf.data.Options()\n",
        "  option_no_order.experimental_deterministic = False\n",
        "\n",
        "  dataset = tf.data.TFRecordDataset(dataset_filenames, num_parallel_reads=AUTO)\n",
        "  dataset = dataset.with_options(option_no_order)\n",
        "  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "  return dataset\n",
        "\n",
        "def get_dataset(training_filenames):\n",
        "  \"\"\" Read dataset from tfrecords, shuffle and prefetch it\"\"\"\n",
        "\n",
        "  dataset = load_tfrecord_dataset(training_filenames)\n",
        "  dataset = dataset.shuffle(2048)\n",
        "  dataset = dataset.prefetch(AUTO)\n",
        "\n",
        "  return dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZm3SAkOyLtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4650aae0-efc9-45c5-99bc-e6f422437e44"
      },
      "source": [
        "# getting image paths\n",
        "IMAGE_SIZE = [331, 331]\n",
        "\n",
        "GCS_PATH = \"gs://kds-b2e6cdbc4af76dcf0363776c09c12fe46872cab211d1de9f60ec7aec\" # GCS path for competition data\n",
        "\n",
        "# dict for paths to different image sizes\n",
        "GCS_PATH_SELECT = { # available image sizes\n",
        "    192: GCS_PATH + '/tfrecords-jpeg-192x192',\n",
        "    224: GCS_PATH + '/tfrecords-jpeg-224x224',\n",
        "    331: GCS_PATH + '/tfrecords-jpeg-331x331',\n",
        "    512: GCS_PATH + '/tfrecords-jpeg-512x512'\n",
        "}\n",
        "\n",
        "# get full path with image size and split to train / val / test\n",
        "GCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n",
        "\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n",
        "TRAINING_FILENAMES = TRAINING_FILENAMES \n",
        "VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n",
        "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') # predictions on this dataset should be submitted for the competition\n",
        "\n",
        "# get length of datasets\n",
        "TRAINING_LENGTH = count_data_items(TRAINING_FILENAMES)\n",
        "VALIDATION_LENGTH = count_data_items(VALIDATION_FILENAMES)\n",
        "TEST_LENGTH = count_data_items(TEST_FILENAMES)\n",
        "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(TRAINING_LENGTH,VALIDATION_LENGTH, TEST_LENGTH))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 16465 training images, 7382 unlabeled test images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMJ0psj1ZLMd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86e773f5-1d7b-4b3a-8056-ff6ef0e3c832"
      },
      "source": [
        "whole_dataset = get_dataset(TRAINING_FILENAMES + VALIDATION_FILENAMES)\n",
        "training_dataset = get_dataset(TRAINING_FILENAMES)\n",
        "validation_dataset = load_tfrecord_dataset(VALIDATION_FILENAMES)\n",
        "test_dataset = load_tfrecord_dataset(TEST_FILENAMES) # have to create a function to load test items from tfrecord\n",
        "\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "STEPS_PER_EPOCH = (TRAINING_LENGTH+ VALIDATION_LENGTH) // BATCH_SIZE\n",
        "batched_whole_dataset = whole_dataset.batch(BATCH_SIZE)\n",
        "batched_training_dataset = training_dataset.batch(BATCH_SIZE)\n",
        "batched_validation_dataset = validation_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "### testing paragraph\n",
        "batched_whole_dataset = whole_dataset.batch(BATCH_SIZE)\n",
        "print(\"Steps per epoch: {}\".format(STEPS_PER_EPOCH))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch: 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRvh9z_1sMPj",
        "colab_type": "text"
      },
      "source": [
        "## Flower classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O53AaKRw0ihG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n",
        "           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n",
        "           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n",
        "           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n",
        "           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n",
        "           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n",
        "           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n",
        "           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n",
        "           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n",
        "           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n",
        "           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGN9A73Zdjh0",
        "colab_type": "text"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFgKgJRvdntA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_image(image, label):\n",
        "  \n",
        "  \"\"\"Randomly flip and saturate an image. args: image, label\"\"\"\n",
        "  aug_image = tf.image.random_flip_left_right(image)\n",
        "  #aug_image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
        "\n",
        "  return aug_image, label\n",
        "\n",
        "\n",
        "def augment_tf_dataset(dataset):\n",
        "  double_data = dataset\n",
        "  \n",
        "  return double_data.map(augment_image, num_parallel_calls=AUTO)\n",
        "  \n",
        "whole_batched_aug_dataset = augment_tf_dataset(whole_dataset).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAIFHa-WbyIb",
        "colab_type": "text"
      },
      "source": [
        "# Simple transfer learning model\n",
        "\n",
        "*   untrainable weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6FfS32qhxIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pretrained_model(trainable=False):\n",
        "  # get xception / densenet pretrained model\n",
        "  #pretrained = keras.applications.Xception(include_top=False, input_shape=[*IMAGE_SIZE,3])\n",
        "  pretrained = tf.keras.applications.DenseNet201(include_top=False, input_shape=[*IMAGE_SIZE,3], weights='imagenet')\n",
        "  pretrained.trainable = trainable\n",
        "\n",
        "  # define model\n",
        "  model = tf.keras.models.Sequential([\n",
        "    pretrained,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUPw5N73elYj",
        "colab_type": "code",
        "outputId": "60844e2a-a7a3-469c-8f53-533ade3d50aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "with strategy.scope():\n",
        "  model = get_pretrained_model()\n",
        "  model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-200ee5f81907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-40ec938c79e5>\u001b[0m in \u001b[0;36mget_pretrained_model\u001b[0;34m(trainable)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# get xception / densenet pretrained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;31m#pretrained = tf.keras.applications.DenseNet201(include_top=False, input_shape=[*IMAGE_SIZE,3], weights='imagenet')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/applications/xception.py\u001b[0m in \u001b[0;36mXception\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    175\u001b[0m   x = layers.SeparableConv2D(\n\u001b[1;32m    176\u001b[0m       256, (3, 3), padding='same', use_bias=False, name='block3_sepconv1')(x)\n\u001b[0;32m--> 177\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block3_sepconv1_bn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block3_sepconv2_act'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m   x = layers.SeparableConv2D(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    921\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     output, mean, variance = tf_utils.smart_cond(training, train_op,\n\u001b[0;32m--> 598\u001b[0;31m                                                  _fused_batch_norm_inference)\n\u001b[0m\u001b[1;32m    599\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_add_or_remove_bessels_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     63\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m     64\u001b[0m   return smart_module.smart_cond(\n\u001b[0;32m---> 65\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n\u001b[0;32m---> 59\u001b[0;31m                                  name=name)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1175\u001b[0m   if (util.EnableControlFlowV2(ops.get_default_graph()) and\n\u001b[1;32m   1176\u001b[0m       not context.executing_eagerly()):\n\u001b[0;32m-> 1177\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcond_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m   \u001b[0;31m# We needed to make true_fn/false_fn keyword arguments for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36mcond_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mfalse_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_captures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mbuilding_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         name=scope)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_build_cond\u001b[0;34m(pred, true_graph, false_graph, true_inputs, false_inputs, building_gradient, name)\u001b[0m\n\u001b[1;32m    272\u001b[0m         output_shapes=_get_output_shapes(true_graph.outputs,\n\u001b[1;32m    273\u001b[0m                                          false_graph.outputs),\n\u001b[0;32m--> 274\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m   \u001b[0mif_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_op_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_functional_ops.py\u001b[0m in \u001b[0;36m_if\u001b[0;34m(cond, input, Tout, then_branch, else_branch, output_shapes, name)\u001b[0m\n\u001b[1;32m    329\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m    330\u001b[0m         \u001b[0;34m\"If\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthen_branch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthen_branch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m               else_branch=else_branch, output_shapes=output_shapes, name=name)\n\u001b[0m\u001b[1;32m    332\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    412\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m               \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m               as_ref=input_arg.is_ref)\n\u001b[0m\u001b[1;32m    415\u001b[0m           if input_arg.number_attr and len(\n\u001b[1;32m    416\u001b[0m               set(v.dtype.base_dtype for v in values)) > 1:\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_n_to_tensor\u001b[0;34m(values, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m             ctx=ctx))\n\u001b[0m\u001b[1;32m   1410\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1307\u001b[0m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[1;32m   1308\u001b[0m                            \"building a function.\")\n\u001b[0;32m-> 1309\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m       \u001b[0;31m# Large EagerTensors and resources are captured with Placeholder ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m       placeholder = _create_substitute_placeholder(\n\u001b[0;32m--> 650\u001b[0;31m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[0m\u001b[1;32m    651\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_capture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1122\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     placeholder = graph_placeholder(\n\u001b[0;32m-> 1124\u001b[0;31m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   1125\u001b[0m   \u001b[0mcustom_gradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     38\u001b[0m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m     39\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m       attrs=attrs, name=name)\n\u001b[0m\u001b[1;32m     41\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3325\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3327\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3328\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 1817\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   1818\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m   \u001b[0;31m# Add attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m     \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m     \u001b[0;31m# TODO(skyewm): this creates and deletes a new TF_Status for every attr.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/_collections_abc.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d3dc58ce-ceac-4c09-cf5c-991de35be20d",
        "id": "jjzneidWU68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "hist = model.fit(batched_training_dataset, epochs=10, validation_data=batched_validation_dataset)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5ecd4de8ecb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_training_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatched_validation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m                 ))\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_function'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fscope'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_per_replica\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fn, args, kwargs, options)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mtpu_run\u001b[0;34m(self, fn, args, kwargs, options)\u001b[0m\n\u001b[1;32m    863\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtpu_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu_function_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_tpu_function_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mtpu_function\u001b[0;34m(args, kwargs)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mdevice_assignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device_assignment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0mmaximum_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m             padding_spec=padding_spec)\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m       \u001b[0;31m# Remove all no ops that may have been added during 'tpu.replicate()'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/tpu/tpu.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(computation, inputs, infeed_queue, device_assignment, name, maximum_shapes, padding_spec)\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m       \u001b[0mmaximum_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m       padding_spec=padding_spec)[1]\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/tpu/tpu.py\u001b[0m in \u001b[0;36msplit_compile_and_replicate\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1278\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_custom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcomputation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_use_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_use_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mreplicated_fn\u001b[0;34m(replica_id, replica_args, replica_kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;34m\"\"\"Wraps user function to provide replica ID and `Tensor` inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_TPUReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplica_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m           \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreplica_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mreplica_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_whitelisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;31m# such as loss scaling and gradient clipping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     _minimize(self.distribute_strategy, tape, self.optimizer, loss,\n\u001b[0;32m--> 475\u001b[0;31m               self.trainable_variables)\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_minimize\u001b[0;34m(strategy, tape, optimizer, loss, trainable_variables)\u001b[0m\n\u001b[1;32m   1724\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scaled_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1726\u001b[0;31m   \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m   \u001b[0;31m# Whether to aggregate gradients outside of optimizer. This requires support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mrespect\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m   \u001b[0mmock_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MockOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m   \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgrad_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, attrs, inputs, outputs, typ, skip_input_indices)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0;34m\"\"\"Pretends to be a tf.Operation for the gradient functions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tCiFwXMhOT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_training_curves(hist.history, metric='sparse_categorical_accuracy', with_val=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SXuIZ3EruzW_",
        "colab": {}
      },
      "source": [
        "display_model_predictions(model, validation_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ALnQXdKvM48",
        "colab_type": "text"
      },
      "source": [
        "# Compute unbalanced class weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB0x2P8hu0d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "y_train = training_dataset.map(lambda image, label: label).as_numpy_iterator()\n",
        "y_train = [x for x in y_train]\n",
        "class_weights = class_weight.compute_class_weight('balanced', [x for x in range(len(CLASSES))], y_train)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))} # converting to dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBMLF3iE7U9E",
        "colab_type": "text"
      },
      "source": [
        "# Transfer learning with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1oOqjE0Ms4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "7a8cba53-4027-457f-83f7-45fd8feb06c0"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = get_pretrained_model(trainable=True)\n",
        "  model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet201 (Model)          (None, 10, 10, 1920)      18321984  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 104)               199784    \n",
            "=================================================================\n",
            "Total params: 18,521,768\n",
            "Trainable params: 18,292,712\n",
            "Non-trainable params: 229,056\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Rnb9g97hsb",
        "colab_type": "code",
        "outputId": "7098d135-70ce-4ca4-d83a-2bc7d7f3e30d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "def step_lr_schedule(epoch, current, decay_rate=0.8, initial_lr=1e-5, linear_slope= 1e-5, peak_slope=5):\n",
        "  \"\"\"transfer learning step scheduler. args: epoch number, curren learning rate\"\"\"\n",
        "  if epoch <= peak_slope:\n",
        "    return initial_lr + linear_slope * epoch\n",
        "  else:\n",
        "    return current * decay_rate**(epoch-peak_slope)\n",
        "\n",
        "def get_transfer_learning_schedule(decay_rate=0.8, initial_lr=1e-5, linear_slope=1e-5, peak_slope=5):\n",
        "  \"\"\"Get a learning rate step scheduler. args: parameters for the step curve\"\"\"\n",
        "  return lambda epoch, current: step_lr_schedule(epoch, current, decay_rate, initial_lr, linear_slope, peak_slope)\n",
        "\n",
        "def plot_lr_schedule(lr_schedule, num_epochs):\n",
        "  current = 0 # initial learning rate\n",
        "  lrs = []\n",
        "  epochs = range(num_epochs)\n",
        "  for epoch in epochs:\n",
        "    lr = lr_schedule(epoch, current)\n",
        "    current = lr # change current learning rate to function outcome\n",
        "    lrs.append(lr)\n",
        "\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(epochs, lrs)\n",
        "\n",
        "transfer_lr_schedule = get_transfer_learning_schedule(decay_rate=0.97, initial_lr=1e-5, linear_slope=4e-5, peak_slope=5)\n",
        "schedule = tf.keras.callbacks.LearningRateScheduler(transfer_lr_schedule, verbose=1)\n",
        "\n",
        "# visualize lr\n",
        "plot_lr_schedule(transfer_lr_schedule, 20)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj1vd1sr-Y_3",
        "colab_type": "code",
        "outputId": "b5e3e8de-19d5-4174-eeeb-902199fec8b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = model.fit(batched_training_dataset, epochs = 25, callbacks=[schedule], validation_data=batched_validation_dataset)#class_weight=class_weights)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 139s 1s/step - loss: 4.1484 - sparse_categorical_accuracy: 0.1416 - val_loss: 3.5351 - val_sparse_categorical_accuracy: 0.3031 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 5e-05.\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 2.0147 - sparse_categorical_accuracy: 0.6016 - val_loss: 1.1241 - val_sparse_categorical_accuracy: 0.7516 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 9e-05.\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 50s 503ms/step - loss: 0.8394 - sparse_categorical_accuracy: 0.8369 - val_loss: 0.5143 - val_sparse_categorical_accuracy: 0.8809 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00013000000000000002.\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.4022 - sparse_categorical_accuracy: 0.9290 - val_loss: 0.3936 - val_sparse_categorical_accuracy: 0.9065 - lr: 1.3000e-04\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.00017.\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 0.1947 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.3395 - val_sparse_categorical_accuracy: 0.9124 - lr: 1.7000e-04\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00021.\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.3357 - val_sparse_categorical_accuracy: 0.9189 - lr: 2.1000e-04\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0002036999983829446.\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.3412 - val_sparse_categorical_accuracy: 0.9176 - lr: 2.0370e-04\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.00019166132437094347.\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.0317 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.2924 - val_sparse_categorical_accuracy: 0.9302 - lr: 1.9166e-04\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0001749241169428278.\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 52s 523ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.2950 - val_sparse_categorical_accuracy: 0.9286 - lr: 1.7492e-04\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00015485906579721108.\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 0.0136 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.2817 - val_sparse_categorical_accuracy: 0.9318 - lr: 1.5486e-04\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 0.000132982749370438.\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.2848 - val_sparse_categorical_accuracy: 0.9343 - lr: 1.3298e-04\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 0.00011077090795011739.\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.2699 - val_sparse_categorical_accuracy: 0.9362 - lr: 1.1077e-04\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 8.950099530095014e-05.\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 0.0069 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2630 - val_sparse_categorical_accuracy: 0.9405 - lr: 8.9501e-05\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 7.014580999533369e-05.\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 0.0058 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.2787 - val_sparse_categorical_accuracy: 0.9345 - lr: 7.0146e-05\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 5.332702496272392e-05.\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 0.0047 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2640 - val_sparse_categorical_accuracy: 0.9388 - lr: 5.3327e-05\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 3.932463480881153e-05.\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 0.0038 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2633 - val_sparse_categorical_accuracy: 0.9423 - lr: 3.9325e-05\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 2.8128965654260245e-05.\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 0.0038 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2600 - val_sparse_categorical_accuracy: 0.9421 - lr: 2.8129e-05\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 1.951706742813227e-05.\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2575 - val_sparse_categorical_accuracy: 0.9429 - lr: 1.9517e-05\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 1.3135514746335399e-05.\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 49s 491ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2607 - val_sparse_categorical_accuracy: 0.9421 - lr: 1.3136e-05\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 8.575340430527574e-06.\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 0.0032 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2606 - val_sparse_categorical_accuracy: 0.9423 - lr: 8.5753e-06\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to 5.4303448039250586e-06.\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 49s 493ms/step - loss: 0.0031 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2604 - val_sparse_categorical_accuracy: 0.9423 - lr: 5.4303e-06\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to 3.335609272385342e-06.\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 49s 491ms/step - loss: 0.0032 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2616 - val_sparse_categorical_accuracy: 0.9421 - lr: 3.3356e-06\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to 1.987442914175041e-06.\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.2610 - val_sparse_categorical_accuracy: 0.9429 - lr: 1.9874e-06\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to 1.1486450922392438e-06.\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 49s 491ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.2603 - val_sparse_categorical_accuracy: 0.9421 - lr: 1.1486e-06\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to 6.439450496831112e-07.\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 54s 537ms/step - loss: 0.0030 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.2602 - val_sparse_categorical_accuracy: 0.9429 - lr: 6.4395e-07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EizdNda7wtBK",
        "colab_type": "text"
      },
      "source": [
        "# Custom cnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elE2A6pAwsF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, GlobalAveragePooling2D, BatchNormalization, MaxPooling2D, concatenate, Input\n",
        "from tensorflow.keras import  Model\n",
        "\n",
        "def inception_block(x, num_3_filters, num_1_filters, batch_norm_moment = 0.9):\n",
        "  side_pool = MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "  # middle branch\n",
        "  middle_branch_1 = Conv2D(num_1_filters, kernel_size=(1,1), strides=(1,1), activation = 'relu', padding='same')(x)\n",
        "  middle_branch_1 = BatchNormalization(momentum=batch_norm_moment)(middle_branch_1)\n",
        "  middle_branch_3 = Conv2D(num_3_filters, kernel_size=(3,3), strides=(2,2), activation='relu', padding='same')(middle_branch_1)\n",
        "  middle_branch_3 = BatchNormalization(momentum=batch_norm_moment)(middle_branch_3)\n",
        "\n",
        "  # big branch\n",
        "  big_branch_1 = Conv2D(num_1_filters, kernel_size=(1,1), strides=(1,1), activation = 'relu', padding='same')(x)\n",
        "  big_branch_1 = BatchNormalization(momentum=batch_norm_moment)(big_branch_1)\n",
        "  big_branch_3_1 = Conv2D(num_3_filters, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(big_branch_1)\n",
        "  big_branch_3_1 = BatchNormalization(momentum=batch_norm_moment)(big_branch_3_1)\n",
        "  big_branch_3_2 = Conv2D(num_3_filters, kernel_size=(3,3), strides=(2,2), activation='relu', padding='same')(big_branch_3_1)\n",
        "  big_branch_3_2 = BatchNormalization(momentum=batch_norm_moment)(big_branch_3_2)\n",
        "\n",
        "  depth_concat = concatenate([side_pool, middle_branch_3, big_branch_3_2])\n",
        "  \n",
        "  return depth_concat\n",
        "\n",
        "def inception(num_3_filters, num_1_filters, batch_norm_moment = 0.9):\n",
        "  return lambda x: inception_block(x, num_3_filters, num_1_filters, batch_norm_moment = 0.9)\n",
        "\n",
        "x = Input(shape=[*IMAGE_SIZE, 3])\n",
        "c1 = Conv2D(6, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "i1 = inception(24,12)(c1)\n",
        "g = GlobalAveragePooling2D()(i1)\n",
        "d = Dense(len(CLASSES), activation='softmax')(g)\n",
        "model = Model(inputs=x, outputs=d)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgaHQCWOuWWw",
        "colab_type": "text"
      },
      "source": [
        "# Apply object detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLL7TKnjQDp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/endernewton/tf-faster-rcnn.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMdjIFZrvGu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}