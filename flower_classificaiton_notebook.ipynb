{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flower_classificaiton_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omerhac/flower_calssification/blob/master/flower_classificaiton_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USMM_qfjDu8-",
        "colab_type": "code",
        "outputId": "fc50a82b-677b-4600-ad2a-9b57d057069a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from matplotlib import pyplot as plt\n",
        "import math, os, sys, re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "if 'google.colab' in sys.modules: # Colab-only Tensorflow version selector\n",
        "  %tensorflow_version 2.x\n",
        "print(\"tf version: \" + tf.__version__)\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf version: 2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn3EgdyMHxAG",
        "colab_type": "text"
      },
      "source": [
        "# Hardware detection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0A8eT_2Ew9l",
        "colab_type": "code",
        "outputId": "75687111-35cf-4550-915f-bd7ee6d21d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "    \n",
        "# Select appropriate distribution strategy for hardware\n",
        "if tpu:\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "  print('Running on TPU ', tpu.master())  \n",
        "elif len(gpus) > 0:\n",
        "  strategy = tf.distribute.MirroredStrategy(gpus) # this works for 1 to multiple GPUs\n",
        "  print('Running on ', len(gpus), ' GPU(s) ')\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "\n",
        "# How many accelerators do we have ?\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.100.98.218:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.100.98.218:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  grpc://10.100.98.218:8470\n",
            "Number of accelerators:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qdxH0sFg0O4",
        "colab_type": "text"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HX6iy3LZdNM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_numpy_batch(dataset, n_samples):\n",
        "  \"\"\"get numpy array of n samples\"\"\"\n",
        "  dataset = dataset.shuffle(buffer_size=10)\n",
        "  batched = dataset.batch(n_samples)\n",
        "  for images, labels in batched:\n",
        "    return images.numpy(), labels.numpy()\n",
        "\n",
        "def show_n_samples(dataset, n):\n",
        "  \"\"\"prints n images and labels\"\"\"\n",
        "  plt.figure(figsize = (2 * n, 2 *n))\n",
        "\n",
        "  rows = math.ceil(n / 3)\n",
        "\n",
        "  batch_images, batch_labels = get_numpy_batch(dataset, n)\n",
        "\n",
        "  for i, image in enumerate(batch_images):\n",
        "    plt.subplot(rows, 3, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(CLASSES[batch_labels[i]])\n",
        "  \n",
        "  plt.show()\n",
        "\n",
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    return np.sum(n)\n",
        "\n",
        "def count_dataset_items(dataset):\n",
        "  # counts items iterativly in the data set. requaiers some time...\n",
        "  count = 0\n",
        "  for obj in dataset:\n",
        "    count += 1\n",
        "  \n",
        "  return count\n",
        "\n",
        "def display_training_curves(hist, metric='accuracy', with_val=False):\n",
        "  \"\"\"display learning curves for keras history dict, args: history dict, with val --> boolean with/without val\"\"\"\n",
        "  plt.figure(figsize=(18,6))\n",
        "\n",
        "  # accuracy plots\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(hist[metric])\n",
        "  \n",
        "  if with_val:\n",
        "    plt.plot(hist['val_' + metric])\n",
        "    plt.legend(['Train', 'Validation'])\n",
        "  \n",
        "  else:\n",
        "    plt.legend(['Train'])\n",
        "  \n",
        "  plt.title('Model accuracy')\n",
        "  plt.xlabel('EPOCH')\n",
        "  plt.ylabel('Accuracy')\n",
        "\n",
        "  # loss plots\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(hist['loss'])\n",
        "\n",
        "  if with_val:\n",
        "    plt.plot(hist['val_loss'])\n",
        "    plt.legend(['Train loss', 'Val loss'])\n",
        "  \n",
        "  else:\n",
        "    plt.legend(['Train loss'])\n",
        "  \n",
        "  plt.title('Model loss')\n",
        "  plt.xlabel('EPOCH')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.show()\n",
        "\n",
        "def display_training_curves_without_dict(accuracy, val_accuracy, loss, val_loss):\n",
        "  \"\"\"display learning curves. args: accuracy iterable, val iterable , loss iterable, val_los iterable\"\"\"\n",
        "  keras_dict = {'accuracy': accuracy, 'val_accuracy': val_accuracy, 'loss': loss, 'val_loss': val_loss}\n",
        "  return display_training_curves(keras_dict)\n",
        "\n",
        "  \n",
        "def display_model_predictions(model, dataset):\n",
        "  \"\"\"Displays 9 images and their predictions\"\"\"\n",
        "\n",
        "  batch_images, batch_labels = get_numpy_batch(dataset, 9)\n",
        "  predictions = model.predict(batch_images) # predict images labels\n",
        "  \n",
        "  plt.figure(figsize=(18,18))\n",
        "\n",
        "  for i, image in enumerate(batch_images):\n",
        "    # def plot\n",
        "    plt.subplot(3,3,i + 1)\n",
        "    plt.imshow(image)\n",
        "\n",
        "    # write prediction as titles\n",
        "    pred =np.argmax(predictions[i])\n",
        "    if pred == batch_labels[i]:\n",
        "      plt.title(CLASSES[pred], fontdict={'color':'g'})\n",
        "\n",
        "    else:\n",
        "      plt.title(CLASSES[pred] + \" WRONG --> \" + CLASSES[batch_labels[i]], fontdict={'color': 'r'})\n",
        "    \n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZX-QcX8TRLN",
        "colab_type": "text"
      },
      "source": [
        "# Loading images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YvIAPRyVMBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read tfrecords from gcs\n",
        "def read_tfrecord(example):\n",
        "  \"\"\"Parses one tf record to image, class, one_hot_class\"\"\"\n",
        "  features = {\n",
        "      \"image\": tf.io.FixedLenFeature([], tf.string),\n",
        "      \"class\": tf.io.FixedLenFeature([], tf.int64),\n",
        "  }\n",
        "\n",
        "  example = tf.io.parse_example(example, features)\n",
        "  image = tf.image.decode_jpeg(example['image'], channels=3)\n",
        "  image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "  image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size will be needed for TPU\n",
        "  label = tf.cast(example['class'], tf.int32)\n",
        "  return image, label\n",
        "\n",
        "def load_tfrecord_dataset(dataset_filenames):\n",
        "  \"\"\"Loads a TFRecord dataset. args: dataset_filnames --> list of strings of files paths\"\"\"\n",
        "\n",
        "  # allows for no order parallel reading\n",
        "  option_no_order = tf.data.Options()\n",
        "  option_no_order.experimental_deterministic = False\n",
        "\n",
        "  dataset = tf.data.TFRecordDataset(dataset_filenames, num_parallel_reads=AUTO)\n",
        "  dataset = dataset.with_options(option_no_order)\n",
        "  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "  return dataset\n",
        "\n",
        "def get_dataset(training_filenames):\n",
        "  \"\"\" Read dataset from tfrecords, shuffle and prefetch it\"\"\"\n",
        "\n",
        "  dataset = load_tfrecord_dataset(training_filenames)\n",
        "  dataset = dataset.shuffle(2048)\n",
        "  dataset = dataset.prefetch(AUTO)\n",
        "\n",
        "  return dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZm3SAkOyLtS",
        "colab_type": "code",
        "outputId": "3e71bc7b-331b-4064-8036-f27834652141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# getting image paths\n",
        "IMAGE_SIZE = [331, 331]\n",
        "\n",
        "GCS_PATH = \"gs://kds-b2e6cdbc4af76dcf0363776c09c12fe46872cab211d1de9f60ec7aec\" # GCS path for competition data\n",
        "\n",
        "# dict for paths to different image sizes\n",
        "GCS_PATH_SELECT = { # available image sizes\n",
        "    192: GCS_PATH + '/tfrecords-jpeg-192x192',\n",
        "    224: GCS_PATH + '/tfrecords-jpeg-224x224',\n",
        "    331: GCS_PATH + '/tfrecords-jpeg-331x331',\n",
        "    512: GCS_PATH + '/tfrecords-jpeg-512x512'\n",
        "}\n",
        "\n",
        "# get full path with image size and split to train / val / test\n",
        "GCS_PATH = GCS_PATH_SELECT[IMAGE_SIZE[0]]\n",
        "\n",
        "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n",
        "TRAINING_FILENAMES = TRAINING_FILENAMES #+ TRAINING_FILENAMES # repeat dataset\n",
        "VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n",
        "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') # predictions on this dataset should be submitted for the competition\n",
        "\n",
        "# get length of datasets\n",
        "TRAINING_LENGTH = count_data_items(TRAINING_FILENAMES)\n",
        "VALIDATION_LENGTH = count_data_items(VALIDATION_FILENAMES)\n",
        "TEST_LENGTH = count_data_items(TEST_FILENAMES)\n",
        "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(TRAINING_LENGTH,VALIDATION_LENGTH, TEST_LENGTH))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 12753 training images, 3712 validation images, 7382 unlabeled test images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMJ0psj1ZLMd",
        "colab_type": "code",
        "outputId": "a7e56c99-bc87-4c3d-f3ff-e59fed78236c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "whole_dataset = get_dataset(TRAINING_FILENAMES + VALIDATION_FILENAMES)\n",
        "training_dataset = get_dataset(TRAINING_FILENAMES)\n",
        "validation_dataset = load_tfrecord_dataset(VALIDATION_FILENAMES)\n",
        "test_dataset = load_tfrecord_dataset(TEST_FILENAMES) # have to create a function to load test items from tfrecord\n",
        "\n",
        "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
        "STEPS_PER_EPOCH = (TRAINING_LENGTH+ VALIDATION_LENGTH) // BATCH_SIZE\n",
        "batched_whole_dataset = whole_dataset.batch(BATCH_SIZE)\n",
        "batched_training_dataset = training_dataset.batch(BATCH_SIZE)\n",
        "batched_validation_dataset = validation_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "### testing paragraph\n",
        "batched_whole_dataset = whole_dataset.batch(BATCH_SIZE)\n",
        "print(\"Steps per epoch: {}\".format(STEPS_PER_EPOCH))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch: 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRvh9z_1sMPj",
        "colab_type": "text"
      },
      "source": [
        "## Flower classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O53AaKRw0ihG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES = ['pink primrose',    'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea',     'wild geranium',     'tiger lily',           'moon orchid',              'bird of paradise', 'monkshood',        'globe thistle',         # 00 - 09\n",
        "           'snapdragon',       \"colt's foot\",               'king protea',      'spear thistle', 'yellow iris',       'globe-flower',         'purple coneflower',        'peruvian lily',    'balloon flower',   'giant white arum lily', # 10 - 19\n",
        "           'fire lily',        'pincushion flower',         'fritillary',       'red ginger',    'grape hyacinth',    'corn poppy',           'prince of wales feathers', 'stemless gentian', 'artichoke',        'sweet william',         # 20 - 29\n",
        "           'carnation',        'garden phlox',              'love in the mist', 'cosmos',        'alpine sea holly',  'ruby-lipped cattleya', 'cape flower',              'great masterwort', 'siam tulip',       'lenten rose',           # 30 - 39\n",
        "           'barberton daisy',  'daffodil',                  'sword lily',       'poinsettia',    'bolero deep blue',  'wallflower',           'marigold',                 'buttercup',        'daisy',            'common dandelion',      # 40 - 49\n",
        "           'petunia',          'wild pansy',                'primula',          'sunflower',     'lilac hibiscus',    'bishop of llandaff',   'gaura',                    'geranium',         'orange dahlia',    'pink-yellow dahlia',    # 50 - 59\n",
        "           'cautleya spicata', 'japanese anemone',          'black-eyed susan', 'silverbush',    'californian poppy', 'osteospermum',         'spring crocus',            'iris',             'windflower',       'tree poppy',            # 60 - 69\n",
        "           'gazania',          'azalea',                    'water lily',       'rose',          'thorn apple',       'morning glory',        'passion flower',           'lotus',            'toad lily',        'anthurium',             # 70 - 79\n",
        "           'frangipani',       'clematis',                  'hibiscus',         'columbine',     'desert-rose',       'tree mallow',          'magnolia',                 'cyclamen ',        'watercress',       'canna lily',            # 80 - 89\n",
        "           'hippeastrum ',     'bee balm',                  'pink quill',       'foxglove',      'bougainvillea',     'camellia',             'mallow',                   'mexican petunia',  'bromelia',         'blanket flower',        # 90 - 99\n",
        "           'trumpet creeper',  'blackberry lily',           'common tulip',     'wild rose']                                                                                                                                               # 100 - 102"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGN9A73Zdjh0",
        "colab_type": "text"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFgKgJRvdntA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_scale_and_shift(image, resize_lower_threshold=0.5):\n",
        "  \"\"\" A function that with probability 0.5 takes an image, resize (randomly between resize_lower_threshold and 1) and shifts it by random values.\"\"\"\n",
        "\n",
        "  if np.random.rand() > 0.5:\n",
        "    return image\n",
        "\n",
        "  height, width, _ = image.shape\n",
        "  resize_ratio = np.random.uniform(low=resize_lower_threshold, high=1) # set resize ratio\n",
        "\n",
        "  # get new dimensions\n",
        "  new_height = int(resize_ratio * height)\n",
        "  new_width = int(resize_ratio * width)  \n",
        "\n",
        "  # resize image\n",
        "  resized_image = tf.image.resize(image, size=tf.constant([new_height, new_width], dtype='int32'))\n",
        "\n",
        "  # shit image\n",
        "  new_image = np.random.uniform(size=image.shape) # create ranodm noise image\n",
        "  row_start = np.random.randint(0, high=height-new_height)\n",
        "  column_start = np.random.randint(0, high=width-new_width)\n",
        "  new_image[row_start:row_start+new_height, column_start:column_start+new_width,:] = resized_image\n",
        "\n",
        "  return new_image\n",
        "\n",
        "def augment_image(image, label):\n",
        "  \n",
        "  \"\"\"Randomly flip and saturate an image. args: image, label\"\"\"\n",
        "  aug_image = tf.image.random_flip_left_right(image)\n",
        "  aug_image = random_scale_and_shift(image)\n",
        "\n",
        "  return aug_image, label\n",
        "\n",
        "\n",
        "def augment_tf_dataset(dataset):\n",
        "  double_data = dataset\n",
        "  \n",
        "  return double_data.map(augment_image, num_parallel_calls=AUTO)\n",
        "  \n",
        "aug_batched_training_dataset = augment_tf_dataset(training_dataset).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAIFHa-WbyIb",
        "colab_type": "text"
      },
      "source": [
        "# Simple transfer learning model\n",
        "\n",
        "*   untrainable weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6FfS32qhxIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pretrained_model(trainable=False):\n",
        "  # get xception / densenet pretrained model\n",
        "  #pretrained = keras.applications.Xception(include_top=False, input_shape=[*IMAGE_SIZE,3])\n",
        "  pretrained = tf.keras.applications.DenseNet201(include_top=False, input_shape=[*IMAGE_SIZE,3], weights='imagenet')\n",
        "  pretrained.trainable = trainable\n",
        "\n",
        "  # define model\n",
        "  model = tf.keras.models.Sequential([\n",
        "    pretrained,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(len(CLASSES), activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUPw5N73elYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with strategy.scope():\n",
        "  #model = get_pretrained_model()\n",
        "  #model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jjzneidWU68d",
        "colab": {}
      },
      "source": [
        "#hist = model.fit(batched_training_dataset, epochs=3, validation_data=batched_validation_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tCiFwXMhOT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#display_training_curves(hist.history, metric='sparse_categorical_accuracy', with_val=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SXuIZ3EruzW_",
        "colab": {}
      },
      "source": [
        "#display_model_predictions(model, validation_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ALnQXdKvM48",
        "colab_type": "text"
      },
      "source": [
        "# Compute unbalanced class weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB0x2P8hu0d3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "y_train = training_dataset.map(lambda image, label: label).as_numpy_iterator()\n",
        "y_train = [x for x in y_train]\n",
        "class_weights = class_weight.compute_class_weight('balanced', [x for x in range(len(CLASSES))], y_train)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))} # converting to dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBMLF3iE7U9E",
        "colab_type": "text"
      },
      "source": [
        "# Transfer learning with trainable weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1oOqjE0Ms4Z",
        "colab_type": "code",
        "outputId": "f64c0fdb-d906-4173-8c0b-825cca49be8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "with strategy.scope():\n",
        "  model = get_pretrained_model(trainable=True)\n",
        "  model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet201 (Model)          (None, 10, 10, 1920)      18321984  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 104)               199784    \n",
            "=================================================================\n",
            "Total params: 18,521,768\n",
            "Trainable params: 18,292,712\n",
            "Non-trainable params: 229,056\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5Rnb9g97hsb",
        "colab_type": "code",
        "outputId": "c7b9c4ac-38d3-48b2-ae2b-69307bf4bdb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "def step_lr_schedule(epoch, current, decay_rate=0.8, initial_lr=1e-5, linear_slope= 1e-5, peak_slope=5):\n",
        "  \"\"\"transfer learning step scheduler. args: epoch number, curren learning rate\"\"\"\n",
        "\n",
        "  if epoch <= peak_slope:\n",
        "    return initial_lr + linear_slope * epoch\n",
        "  else:\n",
        "    return current * decay_rate**(epoch-peak_slope)\n",
        "\n",
        "def get_transfer_learning_schedule(decay_rate=0.8, initial_lr=1e-5, linear_slope=1e-5, peak_slope=5):\n",
        "  \"\"\"Get a learning rate step scheduler. args: parameters for the step curve\"\"\"\n",
        "\n",
        "  return lambda epoch, current: step_lr_schedule(epoch, current, decay_rate, initial_lr, linear_slope, peak_slope)\n",
        "\n",
        "def plot_lr_schedule(lr_schedule, num_epochs):\n",
        "  \"\"\" given a learning schedule function, prints its graph\"\"\"\n",
        "\n",
        "  current = 0 # initial learning rate\n",
        "  lrs = []\n",
        "  epochs = range(num_epochs)\n",
        "  for epoch in epochs:\n",
        "    lr = lr_schedule(epoch, current)\n",
        "    current = lr # change current learning rate to function outcome\n",
        "    lrs.append(lr)\n",
        "\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(epochs, lrs)\n",
        "\n",
        "transfer_lr_schedule = get_transfer_learning_schedule(decay_rate=0.97, initial_lr=1e-5, linear_slope=4e-5, peak_slope=5)\n",
        "\n",
        "# visualize lr\n",
        "plot_lr_schedule(transfer_lr_schedule, 20)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKpbOw1q4j3Q",
        "colab_type": "code",
        "outputId": "c8fe66a8-016e-40ed-91ee-1f8adef8ccbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "## creating callbacks\n",
        "schedule = tf.keras.callbacks.LearningRateScheduler(transfer_lr_schedule, verbose=1)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', mode='auto', restore_best_weights=True, patience=3, verbose=1)\n",
        "model_chkpt = tf.keras.callbacks.ModelCheckpoint(filepath='chkpt', monitor='sparse_categorical_crossentropy', verbose=1, period=5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj1vd1sr-Y_3",
        "colab_type": "code",
        "outputId": "4273ee56-1811-4ddd-b9d0-e3bbd36b541c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        }
      },
      "source": [
        "# train_model\n",
        "hist = model.fit(batched_training_dataset, epochs = 25,\n",
        "                 callbacks=[schedule, early_stopping, model_chkpt], validation_data=batched_validation_dataset)#, class_weight=class_weights)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 1/25\n",
            "100/100 [==============================] - 147s 1s/step - sparse_categorical_accuracy: 0.1334 - loss: 4.1681 - val_sparse_categorical_accuracy: 0.2637 - val_loss: 3.5300 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 5e-05.\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 55s 554ms/step - sparse_categorical_accuracy: 0.5809 - loss: 2.0755 - val_sparse_categorical_accuracy: 0.7489 - val_loss: 1.1330 - lr: 5.0000e-05\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 9e-05.\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 55s 554ms/step - sparse_categorical_accuracy: 0.8335 - loss: 0.8567 - val_sparse_categorical_accuracy: 0.8728 - val_loss: 0.5241 - lr: 9.0000e-05\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00013000000000000002.\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 54s 538ms/step - sparse_categorical_accuracy: 0.9243 - loss: 0.4113 - val_sparse_categorical_accuracy: 0.9079 - val_loss: 0.3852 - lr: 1.3000e-04\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.00017.\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - ETA: 0s - sparse_categorical_accuracy: 0.9665 - loss: 0.2065\n",
            "Epoch 00005: saving model to chkpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ea53bb12c397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m hist = model.fit(batched_training_dataset, epochs = 25,\n\u001b[0;32m----> 2\u001b[0;31m                  callbacks=[schedule, early_stopping, model_chkpt], validation_data=batched_validation_dataset)#, class_weight=class_weights)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       \u001b[0;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_remove_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \"\"\"\n\u001b[1;32m   1046\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1047\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 138\u001b[0;31m                           signatures, options)\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# we use the default replica context here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m       \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    955\u001b[0m   \u001b[0;31m# the SavedModel proto itself.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m   \u001b[0mutils_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_variables_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m   \u001b[0mobject_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m   builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,\n\u001b[1;32m    959\u001b[0m                                               export_dir)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0;32m-> 1187\u001b[0;31m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[0m\u001b[1;32m   1188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[1;32m   1134\u001b[0m       \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# _SingleDeviceSaver will use the CPU device when necessary, but initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# read operations should be placed on the SaveableObject's device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaveable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mtensor_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mtensor_slices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object.py\u001b[0m in \u001b[0;36mtensor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# we copy them to CPU on the same machine first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/device:CPU:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m               \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3896\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3898\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3899\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3900\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: File system scheme '[local]' not implemented (file: 'chkpt/variables/variables_temp_baebde1281d94105b5b06d29308f6ae2/part-00000-of-00002')\n\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors. [Op:Identity]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EizdNda7wtBK",
        "colab_type": "text"
      },
      "source": [
        "# Custom cnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elE2A6pAwsF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, GlobalAveragePooling2D, BatchNormalization, MaxPooling2D, concatenate, Input\n",
        "from tensorflow.keras import  Model\n",
        "\n",
        "def inception_block(x, num_3_filters, num_1_filters, batch_norm_moment = 0.9):\n",
        "  side_pool = MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "  # middle branch\n",
        "  middle_branch_1 = Conv2D(num_1_filters, kernel_size=(1,1), strides=(1,1), activation = 'relu', padding='same')(x)\n",
        "  middle_branch_1 = BatchNormalization(momentum=batch_norm_moment)(middle_branch_1)\n",
        "  middle_branch_3 = Conv2D(num_3_filters, kernel_size=(3,3), strides=(2,2), activation='relu', padding='same')(middle_branch_1)\n",
        "  middle_branch_3 = BatchNormalization(momentum=batch_norm_moment)(middle_branch_3)\n",
        "\n",
        "  # big branch\n",
        "  big_branch_1 = Conv2D(num_1_filters, kernel_size=(1,1), strides=(1,1), activation = 'relu', padding='same')(x)\n",
        "  big_branch_1 = BatchNormalization(momentum=batch_norm_moment)(big_branch_1)\n",
        "  big_branch_3_1 = Conv2D(num_3_filters, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu')(big_branch_1)\n",
        "  big_branch_3_1 = BatchNormalization(momentum=batch_norm_moment)(big_branch_3_1)\n",
        "  big_branch_3_2 = Conv2D(num_3_filters, kernel_size=(3,3), strides=(2,2), activation='relu', padding='same')(big_branch_3_1)\n",
        "  big_branch_3_2 = BatchNormalization(momentum=batch_norm_moment)(big_branch_3_2)\n",
        "\n",
        "  depth_concat = concatenate([side_pool, middle_branch_3, big_branch_3_2])\n",
        "  \n",
        "  return depth_concat\n",
        "\n",
        "def inception(num_3_filters, num_1_filters, batch_norm_moment = 0.9):\n",
        "  return lambda x: inception_block(x, num_3_filters, num_1_filters, batch_norm_moment = 0.9)\n",
        "\n",
        "x = Input(shape=[*IMAGE_SIZE, 3])\n",
        "c1 = Conv2D(6, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "i1 = inception(24,12)(c1)\n",
        "g = GlobalAveragePooling2D()(i1)\n",
        "d = Dense(len(CLASSES), activation='softmax')(g)\n",
        "model = Model(inputs=x, outputs=d)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgaHQCWOuWWw",
        "colab_type": "text"
      },
      "source": [
        "# Apply object detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLL7TKnjQDp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/endernewton/tf-faster-rcnn.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xoqaHXC45rl",
        "colab_type": "text"
      },
      "source": [
        "# Key takeaways:\n",
        "* always use tf.keras and not keras!\n",
        "* for a transfer learning model, its really importent to set whether the model is trainable by \"pretrained_model.trainable = True/False\" and not by \"model.layer.trainable = True/False\". not sure why..\n",
        "* transfer learning is really sensitive to changes in anything..\n",
        "* for a transfer learning model training you should do one of the two:\n",
        "  - warmap top layers for some epochs\n",
        "  - use a step curve learning rate\n",
        "  - dont use both!\n",
        "* pay attention to the metric.. sparse_caterogical_accuracy is very different from accuracy. also the los..\n",
        "* class weighting actually didn't let all-trainable model train!!\n",
        "* ***strong augmentation (random_scale_and_shift) could be a problem in transfer learning\n",
        "* image size between 512x512 and 331x331 didnt have any differance\n",
        "* keras callbacks are good and easy to use\n",
        "* there isnt much difference in accuracy on top notch transfer learning models"
      ]
    }
  ]
}